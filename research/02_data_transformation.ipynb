{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paladin/Downloads/Facial_Impression_Recognition_Calassification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    local_train_dir: Path\n",
    "    local_val_dir: Path\n",
    "    local_test_dir: Path\n",
    "    local_train_file: Path\n",
    "    local_val_file: Path\n",
    "    local_test_file: Path\n",
    "    local_target_file: Path\n",
    "    local_preprocessor_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 16:32:11.243402: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-26 16:32:11.313774: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-26 16:32:11.314994: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 16:32:12.606574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from cnnClassifier.exception import CustomException\n",
    "from cnnClassifier.logger import logging\n",
    "\n",
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils import pixel_to_matrix, save_object, create_directories, read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class configurationManeger:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 secret_filepath = SECRET_FILE_PATH,                 \n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath) \n",
    "        self.secret = read_yaml(secret_filepath)        \n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation             \n",
    "\n",
    "        create_directories([config.root_dir, config.local_train_dir, config.local_val_dir, config.local_test_dir])\n",
    "\n",
    "        data_trnsformation_config = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            local_train_dir = config.local_train_dir,\n",
    "            local_val_dir = config.local_val_dir, \n",
    "            local_test_dir = config.local_test_dir,\n",
    "            local_train_file = self.config.data_ingestion.local_train_file,\n",
    "            local_val_file = self.config.data_ingestion.local_val_file,\n",
    "            local_test_file = self.config.data_ingestion.local_test_file,\n",
    "            local_target_file = config.local_target_file,\n",
    "            local_preprocessor_file = config.local_preprocessor_file\n",
    "\n",
    "        )\n",
    "\n",
    "        return data_trnsformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        try:            \n",
    "            face_recognition_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    ('pixel_to_image', \n",
    "                    FunctionTransformer(pixel_to_matrix, kw_args={'img_height':48, 'img_width':48}))\n",
    "                ]\n",
    "            )\n",
    "            return face_recognition_pipeline            \n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    \n",
    "    def initiate_data_transformation(self):\n",
    "        if not os.path.exists(self.config.local_train_file):\n",
    "            logging.info(f\"WARNING: {self.config.local_train_file} does not exist!\")\n",
    "        \n",
    "        elif not os.path.exists(self.config.local_val_file):\n",
    "            logging.info(f\"WARNING: {self.config.local_val_file} does not exist!\")   \n",
    "\n",
    "        elif not os.path.exists(self.config.local_test_file):\n",
    "            logging.info(f\"WARNING: {self.config.local_test_file} does not exist!\")              \n",
    "        \n",
    "        else:  \n",
    "            \n",
    "            train_df = pd.read_csv(self.config.local_train_file)\n",
    "            val_df = pd.read_csv(self.config.local_val_file)\n",
    "            test_df = pd.read_csv(self.config.local_test_file)\n",
    "            logging.info('Read train, validation and test data completed')\n",
    "\n",
    "            logging.info(\"Obtaining preprocessing object\")\n",
    "            preprocessing_obj=self.get_data_transformer_object() \n",
    "            pixel_column = 'pixels'\n",
    "            target_column_name = 'emotion'             \n",
    "\n",
    "            logging.info(f\"Applying preprocessing object on train, validation and test dataframes\")\n",
    "            input_train_arr = preprocessing_obj.fit_transform(train_df[pixel_column])\n",
    "            for i in range(len(input_train_arr)):\n",
    "                path_file = os.path.join(self.config.local_train_dir, str(i)+'.png')\n",
    "                save_img(path_file, input_train_arr[i])\n",
    "            logging.info(f\"Train set is saved as .png\")         \n",
    "            \n",
    "            input_val_arr = preprocessing_obj.fit_transform(val_df[pixel_column])  \n",
    "            for i in range(len(input_val_arr)):\n",
    "                path_file = os.path.join(self.config.local_val_dir, str(i)+'.png')\n",
    "                save_img(path_file, input_val_arr[i])         \n",
    "            logging.info(f\"Validation set is saved as .png\")\n",
    "            \n",
    "            input_test_arr = preprocessing_obj.transform(test_df[pixel_column]) \n",
    "            for i in range(len(input_test_arr)):\n",
    "                path_file = os.path.join(self.config.local_test_dir, str(i)+'.png')\n",
    "                save_img(path_file, input_test_arr[i])  \n",
    "            logging.info(f\"Test set is saved as .png\")\n",
    "            \n",
    "\n",
    "            logging.info(f\"Changing target variable format to match with keras\")\n",
    "            target_train_arr = to_categorical(train_df[target_column_name], 7)   \n",
    "            target_val_arr = to_categorical(val_df[target_column_name], 7)  \n",
    "            target_test_arr = to_categorical(test_df[target_column_name], 7) \n",
    "            \n",
    "            logging.info(f\"Saving target variables as pickel file\")\n",
    "            target_variable = {'train': target_train_arr, 'validation': target_val_arr, 'test': target_test_arr }           \n",
    "            save_object(path=self.config.local_target_file, obj=target_variable)\n",
    "            \n",
    "            logging.info('Saved preprocessing object')\n",
    "            save_object(path=self.config.local_preprocessor_file, obj=preprocessing_obj)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = configurationManeger()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pic \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mX_train[\u001b[39m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m pic\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "pic = data.X_train[1]\n",
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.image' has no attribute 'imwrite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpimg\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mpimg\u001b[39m.\u001b[39;49mimwrite(\u001b[39m'\u001b[39m\u001b[39mname.png\u001b[39m\u001b[39m'\u001b[39m, pic)\n\u001b[1;32m      5\u001b[0m img \u001b[39m=\u001b[39m mpimg\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mname.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m img\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.image' has no attribute 'imwrite'"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "mpimg.imwrite('name.png', pic)\n",
    "\n",
    "img = mpimg.imread('name.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n",
      "(48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "pic = data.X_train[1]\n",
    "pic.shape\n",
    "print(pic.shape)\n",
    "save_img('name1.png', pic)\n",
    "img = load_img('name.png')\n",
    "img_array = img_to_array(img)\n",
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[151., 151., 151.],\n",
       "        [150., 150., 150.],\n",
       "        [147., 147., 147.],\n",
       "        ...,\n",
       "        [129., 129., 129.],\n",
       "        [140., 140., 140.],\n",
       "        [120., 120., 120.]],\n",
       "\n",
       "       [[151., 151., 151.],\n",
       "        [149., 149., 149.],\n",
       "        [149., 149., 149.],\n",
       "        ...,\n",
       "        [122., 122., 122.],\n",
       "        [141., 141., 141.],\n",
       "        [137., 137., 137.]],\n",
       "\n",
       "       [[151., 151., 151.],\n",
       "        [151., 151., 151.],\n",
       "        [156., 156., 156.],\n",
       "        ...,\n",
       "        [109., 109., 109.],\n",
       "        [123., 123., 123.],\n",
       "        [146., 146., 146.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[188., 188., 188.],\n",
       "        [188., 188., 188.],\n",
       "        [121., 121., 121.],\n",
       "        ...,\n",
       "        [185., 185., 185.],\n",
       "        [185., 185., 185.],\n",
       "        [186., 186., 186.]],\n",
       "\n",
       "       [[188., 188., 188.],\n",
       "        [187., 187., 187.],\n",
       "        [196., 196., 196.],\n",
       "        ...,\n",
       "        [186., 186., 186.],\n",
       "        [182., 182., 182.],\n",
       "        [187., 187., 187.]],\n",
       "\n",
       "       [[186., 186., 186.],\n",
       "        [184., 184., 184.],\n",
       "        [185., 185., 185.],\n",
       "        ...,\n",
       "        [193., 193., 193.],\n",
       "        [183., 183., 183.],\n",
       "        [184., 184., 184.]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
